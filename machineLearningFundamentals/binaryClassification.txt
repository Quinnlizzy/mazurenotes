Binary classification

Classification, like regression is SML technique.
Therefore follows same iterative process; training, validating, evaluating models. 

        BUT Instead of calculating numeric values like regression;
            - algorithms used to train classification models calculate probability values for class assignment 
            - & evaluation metrics that assess model performance compare predicted classes to actual classes.

BinClass algorithms used to train model that predicts one of two possible labels for single class
            - Basically; true or false. 
            - Most scenarios; data obs used to train & validate model have multiple feature values(x) and a (y) value = 1 or 0.



Example - binClass
Simplified example using single feature (x) to predict whether label (y) is 1 or 0. 
Use blood glucose level of a patient to predict if has diabetes. Data:

            Blood glucose (x)	Diabetic? (y)
                            67	0
                            103	1
                            114	1
                            72	0
                            116	1
                            65	0


Training binClass model
Use an algorithm to fit training data to function that calculates probability of class label being true (diabetic)
Probability measured as value between 0.0 and 1.0
Total probability for all possible classes = 1.0. 

            E.g. if probability of diabetes = 0.7, then corresponding probability of 0.3 of no diabetes.

Many algorithms can be used for binClass.



Logistic regression algorithm;

Derives sigmoid (S-shaped graph) function with values between 0.0 and 1.0.
Function produced by algorithm describes probability of y being true (y=1) for given value of x. 
Mathematically, express function like this: f(x) = P(y=1 | x)

            For 3.6 obs in training data, we know y is true.
            Therefore, probability for those obs that y=1 is 1.0
            For other three, we know y is false.
            Therefore, probability that y=1 is 0.0. 
            S-shaped curve describes probability distribution; 
            Therefore, plotting a value of x on the line identifies corresponding probability that y is 1.

Model diagram also includes horizontal line. 
This indicates threshold where model based on this func will predict true(1)/false(0).
Threshold lies at mid-point for y (P(y) = 0.5). 
Values at this point or above; model predicts true (1);
Values below will predict false (0). 

            E.g. patient with blood glucose 90; func result in probability value 0.9. 
            0.9 higher than threshold of 0.5 so model predicts true (1) (diabetes).



Evaluating binClass Model
Like regression, hold back random subset of data to validate trained model. 
        
        Assume held back following data to validate our diabetes classifier:
                Blood glucose (x)	Diabetic? (y)
                                66	0
                                107	1
                                112	1
                                71	0
                                87	1
                                89	1
        Applying logistic func derived previously to the x values results in new plot.
        Based on whether probability calculated by func is above/below threshold,
        the model generates predicted label of 1 or 0 for each obs. 
        We then compare predicted class labels (ŷ) to actual class labels (y):

                Blood glucose (x)	Actual diabetes diagnosis (y)	Predicted diabetes diagnosis (ŷ)
                                                66	0	0
                                                107	1	1
                                                112	1	1
                                                71	0	0
                                                87	1	0
                                                89	1	1
    


BinClass evaluation metrics

First step in calc eval metrics for binClass model is to create matrix of no. of correct/incorrect predictions for each 
possible class label:

       Confusion matrix. Shows the prediction totals where:

                            ŷ=0 and y=0: True negatives (TN)
                            ŷ=1 and y=0: False positives (FP)
                            ŷ=0 and y=1: False negatives (FN)
                            ŷ=1 and y=1: True positives (TP)

       The arrangement of confusion matrix shows that correct (true) predictions are shown in a diagonal line from 
       top-left to bottom-right. 
       Often, color-intensity is used to indicate no. of predictions in each cell, 
       (so a quick glance at a model that predicts well should reveal deeply shaded diagonal trend).



Accuracy
The simplest metric you can calculate from the confusion matrix is accuracy - the proportion of predictions that the model got right. Accuracy is calculated as:

(TN+TP) ÷ (TN+FN+FP+TP)

In the case of our diabetes example, the calculation is:

(2+3) ÷ (2+1+0+3)

= 5 ÷ 6

= 0.83

So for our validation data, the diabetes classification model produced correct predictions 83% of the time.

Accuracy might initially seem like a good metric to evaluate a model, but consider this. Suppose 11% of the population has diabetes. You could create a model that always predicts 0, and it would achieve an accuracy of 89%, even though it makes no real attempt to differentiate between patients by evaluating their features. What we really need is a deeper understanding of how the model performs at predicting 1 for positive cases and 0 for negative cases.